# -*- coding: utf-8 -*-
"""Final kNN hyperparameter tuning.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1W2hHMZW_TFgIHHMwc3Fo7_GCD8yXfca0

# Classification

## Importing the libraries
"""

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd

"""## Importing the dataset"""

styleSilentShot = pd.read_excel('1.2 SilentSoundScale_asl_count30+.xlsx')
x = styleSilentShot.iloc[: , 1:-1].values # These are the predictor, independent variables (the 1:-1 excludes the first and last columns)
y = styleSilentShot.iloc[: , -1].values # These are the target variables (or classes, in this case)

print(x[0,:])

styleSilentShot.head()

"""## Taking care of missing data"""

from sklearn.impute import SimpleImputer
imputer = SimpleImputer(missing_values=np.nan, strategy='mean')
imputer.fit(x[: , 1:]) # Only the columns containing the numerical values
x[: , 1:] = imputer.transform(x[: , 1:]) # Update the variable x

"""## Encoding the independent variable"""

from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OneHotEncoder
ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [0])], remainder='passthrough')
x = np.array(ct.fit_transform(x))

"""## Splitting the dataset into the Training set and Test set"""

from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3)

# Print whole matrices 
import sys
import numpy as np
np.set_printoptions(threshold=sys.maxsize)

# print(x_test)

# print(y_test)

"""# kNN"""

from sklearn.neighbors import KNeighborsClassifier
#Train Model and Predict
k = 5  
classifierKNN = KNeighborsClassifier(n_neighbors=k)
classifierKNN.fit(x_train, y_train)

y_pred = classifierKNN.predict(x_test)
np.set_printoptions(precision=2)

from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score
cm = confusion_matrix(y_test, y_pred)
cm = confusion_matrix(y_test, y_pred)
print(cm)

print("Accuracy:",accuracy_score(y_test, y_pred))
print("Precision:",precision_score(y_test, y_pred))
print("Recall:",recall_score(y_test, y_pred))

from sklearn.model_selection import cross_val_score
accuracies = cross_val_score(estimator = classifierKNN, X = x_train, y = y_train, cv = 10) # 10-fold cross validation = 10 different test sets
print("kNN cross-validation")
print("Accuracy: {:.2f} %".format(accuracies.mean()*100)) # Format: float with two decimals
print("Standard deviation: {:.2f} %".format(accuracies.std()*100))

"""## Find optimal value for K using error rates and accuracy

Compare the error rates at different values of K
"""

error_rate = []
for i in range(1,30): # 30 is chosen as the maximum number of K as the
                      # training data comprises 264 instances, the square root of which is 16
 knn = KNeighborsClassifier(n_neighbors=i)
 knn.fit(x_train,y_train)
 pred_i = knn.predict(x_test)
 error_rate.append(np.mean(pred_i != y_test))

plt.figure(figsize=(16,8))
plt.plot(range(1,30),error_rate,color='blue', linestyle='dashed', 
         marker='o',markerfacecolor='red', markersize=10)

plt.rcParams["font.family"] = "serif"
plt.rcParams.update({'font.size': 16})

plt.title('Error Rate vs. K Value')
plt.xlabel('K')
plt.ylabel('Error Rate')
print("Minimum error:-",min(error_rate),"at K =",1+error_rate.index(min(error_rate)))

"""Compare the accuracy rates at different values of K"""

acc = []
# Will take some time
from sklearn import metrics
from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score
for i in range(1,30):
    neigh = KNeighborsClassifier(n_neighbors = i).fit(x_train,y_train)
    yhat = neigh.predict(x_test)
    acc.append(metrics.accuracy_score(y_test, yhat))
    
plt.figure(figsize=(16,8))
plt.plot(range(1,30),acc,color = 'blue',linestyle='dashed', 
         marker='o',markerfacecolor='red', markersize=10)

plt.rcParams["font.family"] = "serif"
plt.rcParams.update({'font.size': 16})

plt.title('Accuracy vs. K Value')
plt.xlabel('K')
plt.ylabel('Accuracy')
print("Maximum accuracy:-",max(acc),"at K =",1+acc.index(max(acc)))

"""## Find optimal value for K using AUC"""

auc_scores = []
# Will take some time
from sklearn import metrics
from sklearn.metrics import roc_curve, auc

for i in range(1,50):
    neigh = KNeighborsClassifier(n_neighbors = i).fit(x_train,y_train)
    yhat = neigh.predict(x_test)
    # Calculate probabilities and determine TPR and FPR
    probs = neigh.predict_proba(x_test)
    # Reading probability of second class (Silent)
    probs = probs[:, 1]
    fpr, tpr, thresholds = roc_curve(y_test, probs)
    roc_auc = auc(fpr, tpr)
    auc_scores.append(roc_auc)

    
plt.figure(figsize=(16,6))
plt.plot(range(1,50), auc_scores, color = 'black',linestyle='solid', 
         marker='.',markerfacecolor='black', markersize=10)

plt.rcParams["font.family"] = "serif"
plt.rcParams.update({'font.size': 18})

plt.title('AUC vs. K-value')
plt.xlabel('K')
plt.ylabel('AUC')
print("Maximum AUC:-",max(auc_scores),"at K =",1+auc_scores.index(max(auc_scores)))