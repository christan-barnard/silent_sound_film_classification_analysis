# -*- coding: utf-8 -*-
"""Final Classification Models: Silent/Sound data.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Ls40s8bUUgdeQszSMGI6G1pn0fMB9iMo

# Preliminary silent-sound classification analysis

## Importing the libraries
"""

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd

"""## Importing the dataset"""

styleSilentShot = pd.read_excel('filmStyleSilentTrimmedForPython.xlsx')
x = styleSilentShot.iloc[: , 1:-1].values # These are the predictor, independent variables (the 1:-1 excludes the first and last columns)
y = styleSilentShot.iloc[: , -1].values # These are the target variables (or classes, in this case)

print(x[0,:])

styleSilentShot.head()

"""## Taking care of missing data"""

from sklearn.impute import SimpleImputer
imputer = SimpleImputer(missing_values=np.nan, strategy='mean')
imputer.fit(x[: , 1:]) # Only the columns containing the numerical values
x[: , 1:] = imputer.transform(x[: , 1:]) # Update the variable x
# print(x[: , 1:])

"""## Encoding the independent variable"""

from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OneHotEncoder
ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [0])], remainder='passthrough')
x = np.array(ct.fit_transform(x))

"""## Splitting the dataset into the Training set and Test set"""

from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2)

# Print whole matrices 
import sys
import numpy as np
np.set_printoptions(threshold=sys.maxsize)

print(x_test)

print(y_test)

"""## Feature Scaling"""

from sklearn.preprocessing import StandardScaler # Using standardisation, not normalisation
sc = StandardScaler()
x_train[: , 11:] = sc.fit_transform(x_train[: , 11:]) # There are 10 columns allocated to the one hot encoded country classes
x_test[: , 11:] = sc.transform(x_test[: , 11:]) # Using the same scaler (fit mean and std dev) as the training data because the test data is "unavailable"

"""# Logistic Regression

## Training the LR model
"""

from sklearn.linear_model import LogisticRegression
classifierLR = LogisticRegression()
classifierLR.fit(x_train, y_train)

"""## Predicting LR Test results"""

y_pred = classifierLR.predict(x_test)
np.set_printoptions(precision=2) # Specify the number of decimals if not a binary target variable
# print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1)) # Col 1 = predictions, Col 2 = actual values

"""## Making the Confusion Matrix"""

from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score
cm = confusion_matrix(y_test, y_pred)
cm = confusion_matrix(y_test, y_pred)
print(cm)

print("Accuracy:",accuracy_score(y_test, y_pred))
print("Precision:",precision_score(y_test, y_pred))
print("Recall:",recall_score(y_test, y_pred))

"""## k-fold cross validation

"""

from sklearn.model_selection import cross_val_score
accuracies = cross_val_score(estimator = classifierLR, X = x_train, y = y_train, cv = 10) # 10-fold cross validation = 10 different test sets
print("Logistic regression cross-validation")
print("Accuracy: {:.2f} %".format(accuracies.mean()*100)) # Format: float with two decimals
print("Standard deviation: {:.2f} %".format(accuracies.std()*100))

"""## Feature selection using wrapper"""

from mlxtend.feature_selection import SequentialFeatureSelector as SFS
# Documentation and math http://rasbt.github.io/mlxtend/user_guide/feature_selection/SequentialFeatureSelector/
# Scoring: accuracy, f1, precision, recall, roc_auc

sfs1 = SFS(estimator = classifierLR,
           k_features = np.shape(x)[1],
           forward=True,
           scoring='accuracy',
           cv=10    
)

sfs1.fit(x_train, y_train)
sfs1.subsets_

"""Print the column headings of the top five features identified by the forward sequential feature selector"""

print("This is the first row of x: 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 6.7 58.0 4.0 2.0 0.0 64.0 224.0 82.0 37.0 36.0 53.0 3.0")

feature_idx = [0, 3, 8, 14, 20] # NB: From the forward sequential feature selector

x_col = ["country", "country", "country", "country", "country", "country", "country", 
         "country", "country", 'ASL',	'RA',	'POV',	'INS',	'INTERTIT',	'BCU',	'CU',	'MCU',	'MS',	'MLS',	'LS',	'VLS']
[ x_col[i] for i in feature_idx ]

# col_names = styleSilentShot[[0, 3, 8, 14, 20] + 1]
# print(col_names)

"""Chech the correlation between these variables: If strong, check your model assumptions"""

styleSilentShot[['BCU', 'VLS']].corr()

"""# kNN"""

from sklearn.neighbors import KNeighborsClassifier
classifierKNN = KNeighborsClassifier(n_neighbors=5)
classifierKNN.fit(x_train, y_train)

y_pred = classifierKNN.predict(x_test)
np.set_printoptions(precision=2)

from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score
cm = confusion_matrix(y_test, y_pred)
cm = confusion_matrix(y_test, y_pred)
print(cm)

print("Accuracy:",accuracy_score(y_test, y_pred))
print("Precision:",precision_score(y_test, y_pred))
print("Recall:",recall_score(y_test, y_pred))

from sklearn.model_selection import cross_val_score
accuracies = cross_val_score(estimator = classifierKNN, X = x_train, y = y_train, cv = 10) # 10-fold cross validation = 10 different test sets
print("kNN cross-validation")
print("Accuracy: {:.2f} %".format(accuracies.mean()*100)) # Format: float with two decimals
print("Standard deviation: {:.2f} %".format(accuracies.std()*100))

"""# Linear SVM"""

from sklearn.svm import SVC
classifierSVM = SVC(kernel='linear')
classifierSVM.fit(x_train, y_train)

y_pred = classifierSVM.predict(x_test)

from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score
cm = confusion_matrix(y_test, y_pred)
print(cm)

print("Accuracy:",accuracy_score(y_test, y_pred))
print("Precision:",precision_score(y_test, y_pred))
print("Recall:",recall_score(y_test, y_pred))

from sklearn.model_selection import cross_val_score
accuracies = cross_val_score(estimator = classifierSVM, X = x_train, y = y_train, cv = 10) # 10-fold cross validation = 10 different test sets
print("Linear SVC cross-validation")
print("Accuracy: {:.2f} %".format(accuracies.mean()*100)) # Format: float with two decimals
print("Standard deviation: {:.2f} %".format(accuracies.std()*100))

"""# Nonlinear SVM

## SVC
"""

from sklearn.svm import SVC
classifierSVMrbf = SVC(kernel='rbf') # kernel{‘linear’, ‘poly’, ‘rbf’, ‘sigmoid’, ‘precomputed’}, default=’rbf’
classifierSVMrbf.fit(x_train, y_train)

y_pred = classifierSVMrbf.predict(x_test)

from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score
cm = confusion_matrix(y_test, y_pred)
print('SVC with kernel = rbf')
print(cm)

print("Accuracy:",accuracy_score(y_test, y_pred))
print("Precision:",precision_score(y_test, y_pred))
print("Recall:",recall_score(y_test, y_pred))

from sklearn.model_selection import cross_val_score
accuracies = cross_val_score(estimator = classifierSVMrbf, X = x_train, y = y_train, cv = 10) # 10-fold cross validation = 10 different test sets
print("SVC with kernel = rbf cross-validation")
print("Accuracy: {:.2f} %".format(accuracies.mean()*100)) # Format: float with two decimals
print("Standard deviation: {:.2f} %".format(accuracies.std()*100))

"""### Grid search hyper-parameter optimisation"""

from sklearn.model_selection import GridSearchCV
parameters = [{'C': [0.25, 0.5, 0.75, 1], 'kernel': ['linear']}, # 'Parameter' and then the [test values] (0.25 = strong regularization = less overfitting)
              {'C': [0.25, 0.5, 0.75, 1], 'kernel': ['poly', 'rbf', 'sigmoid'], 'gamma': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]}]
              # gamma can only be tuned in rbf, poly and sigmoid, so that's why there are two {dictionaries}
grid_search = GridSearchCV(estimator = classifierSVMrbf,
                           param_grid = parameters,
                           scoring = 'accuracy',
                           cv = 10, # 10-fold cross validation
                           n_jobs = -1) # if you are running the code on your machine, this will allocate all the processors to running the code
grid_search.fit(x_train, y_train)
best_accuracy = grid_search.best_score_
best_parameters = grid_search.best_params_

print("SVC with grid search cross-validation")
print("Best accuracy: {:.2f} %".format(best_accuracy*100)) # Format: float with two decimals
print("Best parameters:", best_parameters)

"""## NuSVC"""

from sklearn.svm import NuSVC
classifierNuSVMrbf = NuSVC(kernel='poly') # kernel{‘linear’, ‘poly’, ‘rbf’, ‘sigmoid’, ‘precomputed’}, default=’rbf’
classifierNuSVMrbf.fit(x_train, y_train)

y_pred = classifierNuSVMrbf.predict(x_test)

from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score
cm = confusion_matrix(y_test, y_pred)
print('NuSVC with kernel = rbf')
print(cm)

print("Accuracy:",accuracy_score(y_test, y_pred))
print("Precision:",precision_score(y_test, y_pred))
print("Recall:",recall_score(y_test, y_pred))

from sklearn.model_selection import cross_val_score
accuracies = cross_val_score(estimator = classifierNuSVMrbf, X = x_train, y = y_train, cv = 10) # 10-fold cross validation = 10 different test sets
print("NuSVC with kernel = rbf cross-validation")
print("Accuracy: {:.2f} %".format(accuracies.mean()*100)) # Format: float with two decimals
print("Standard deviation: {:.2f} %".format(accuracies.std()*100))

"""# Naive Bayes

The sklearn.naive_bayes module implements Naive Bayes algorithms. These are supervised learning methods based on applying Bayes’ theorem with strong (naive) feature independence assumptions.

## Gaussian
"""

from sklearn.naive_bayes import GaussianNB
classifierGNB = GaussianNB() 
classifierGNB.fit(x_train, y_train)

y_pred = classifierGNB.predict(x_test)

from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score
cm = confusion_matrix(y_test, y_pred)
print('Gaussian NB')
print(cm)

print("Accuracy:",accuracy_score(y_test, y_pred))
print("Precision:",precision_score(y_test, y_pred))
print("Recall:",recall_score(y_test, y_pred))

from sklearn.model_selection import cross_val_score
accuracies = cross_val_score(estimator = classifierGNB, X = x_train, y = y_train, cv = 10) # 10-fold cross validation = 10 different test sets
print("Gaussian Naive Bayes cross-validation")
print("Accuracy: {:.2f} %".format(accuracies.mean()*100)) # Format: float with two decimals
print("Standard deviation: {:.2f} %".format(accuracies.std()*100))

"""# Decision trees"""

from sklearn.tree import DecisionTreeClassifier
classifierTree = DecisionTreeClassifier(criterion='entropy') # Default is gini
classifierTree.fit(x_train, y_train)

y_pred = classifierTree.predict(x_test)

from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score
cm = confusion_matrix(y_test, y_pred)
print('Decision trees')
print(cm)

print("Accuracy:",accuracy_score(y_test, y_pred))
print("Precision:",precision_score(y_test, y_pred))
print("Recall:",recall_score(y_test, y_pred))

from sklearn.model_selection import cross_val_score
accuracies = cross_val_score(estimator = classifierTree, X = x_train, y = y_train, cv = 10) # 10-fold cross validation = 10 different test sets
print("Decision tree cross-validation")
print("Accuracy: {:.2f} %".format(accuracies.mean()*100)) # Format: float with two decimals
print("Standard deviation: {:.2f} %".format(accuracies.std()*100))

"""## Understanding the tree structure from scikit-learn

This is human-readable, but only interpretable if the variables aren't scaled
"""

n_nodes = classifierTree.tree_.node_count
children_left = classifierTree.tree_.children_left
children_right = classifierTree.tree_.children_right
feature = classifierTree.tree_.feature
threshold = classifierTree.tree_.threshold

node_depth = np.zeros(shape=n_nodes, dtype=np.int64)
is_leaves = np.zeros(shape=n_nodes, dtype=bool)
stack = [(0, 0)]  # start with the root node id (0) and its depth (0)
while len(stack) > 0:
    # `pop` ensures each node is only visited once
    node_id, depth = stack.pop()
    node_depth[node_id] = depth

    # If the left and right child of a node is not the same we have a split
    # node
    is_split_node = children_left[node_id] != children_right[node_id]
    # If a split node, append left and right children and depth to `stack`
    # so we can loop through them
    if is_split_node:
        stack.append((children_left[node_id], depth + 1))
        stack.append((children_right[node_id], depth + 1))
    else:
        is_leaves[node_id] = True

print("The binary tree structure has {n} nodes and has "
      "the following tree structure:\n".format(n=n_nodes))
for i in range(n_nodes):
    if is_leaves[i]:
        print("{space}node={node} is a leaf node.".format(
            space=node_depth[i] * "\t", node=i))
    else:
        print("{space}node={node} is a split node: "
              "go to node {left} if X[:, {feature}] <= {threshold} "
              "else to node {right}.".format(
                  space=node_depth[i] * "\t",
                  node=i,
                  left=children_left[i],
                  feature=feature[i],
                  threshold=threshold[i],
                  right=children_right[i]))

"""## Plotting the tree"""

from sklearn.tree import plot_tree
plot_tree(classifierTree)

plt.rcParams['figure.figsize'] = [24, 16]
plt.rcParams['figure.dpi'] = 200 # 200 e.g. is really fine, but slower
# Alt for the whole notebook: fig=plt.figure(figsize=(12,8), dpi= 100, facecolor='w', edgecolor='k')

plt.show()

"""# Random forests"""

from sklearn.ensemble import RandomForestClassifier
classifierForest = DecisionTreeClassifier(criterion='entropy') # Default is gini
classifierForest.fit(x_train, y_train)

y_pred = classifierForest.predict(x_test)

from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score
cm = confusion_matrix(y_test, y_pred)
print('Random Forest')
print(cm)

print("Accuracy:",accuracy_score(y_test, y_pred))
print("Precision:",precision_score(y_test, y_pred))
print("Recall:",recall_score(y_test, y_pred))

from sklearn.model_selection import cross_val_score
accuracies = cross_val_score(estimator = classifierForest, X = x_train, y = y_train, cv = 10) # 10-fold cross validation = 10 different test sets
print("Random Forest cross-validation")
print("Accuracy: {:.2f} %".format(accuracies.mean()*100)) # Format: float with two decimals
print("Standard deviation: {:.2f} %".format(accuracies.std()*100))

"""# XGBoost"""

from xgboost import XGBClassifier  # NB: xgboost library is already installed on Google Colab, will need to install it manually when working elsewhere
classifierXGB = XGBClassifier() # "ML A-Z lecture: Most of the time the default hyper parameters perform very well"
classifierXGB.fit(x_train, y_train)

y_pred = classifierForest.predict(x_test)

from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score
cm = confusion_matrix(y_test, y_pred)
print('XGBoost')
print(cm)

print("Accuracy:",accuracy_score(y_test, y_pred))
print("Precision:",precision_score(y_test, y_pred))
print("Recall:",recall_score(y_test, y_pred))

from sklearn.model_selection import cross_val_score
accuracies = cross_val_score(estimator = classifierXGB, X = x_train, y = y_train, cv = 10) # 10-fold cross validation = 10 different test sets
print("XGBoost cross-validation")
print("Accuracy: {:.2f} %".format(accuracies.mean()*100)) # Format: float with two decimals
print("Standard deviation: {:.2f} %".format(accuracies.std()*100))